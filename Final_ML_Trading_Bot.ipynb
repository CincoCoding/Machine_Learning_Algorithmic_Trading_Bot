{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9IKCTdp39fW"
   },
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import alpaca_trade_api as tradeapi\n",
    "from finta import TA\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import pandas as pd \n",
    "from pathlib import Path \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "\n",
    "# Initial imports\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# Initial imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the finta Python library and the TA module\n",
    "from finta import TA\n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API credentials\n",
    "ALPACA_API_KEY = 'PKETI0Q5C8PPUXVNHJFJ'\n",
    "ALPACA_SECRET_KEY = 'WQxmEpBCoMXydCCg0G8cUe6hGLpgaAfrvedZ09Fy'\n",
    "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"\n",
    "\n",
    "# Create a connection to the API \n",
    "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, ALPACA_API_BASE_URL, api_version=\"v2\")\n",
    "\n",
    "# Set signal variable\n",
    "signal = 1\n",
    "\n",
    "# Create buy signal, num shares and ticker\n",
    "if signal == 1:\n",
    "    orderSide = \"buy\"\n",
    "else:\n",
    "    orderSide = \"sell\"\n",
    "    \n",
    "# Set the ticket symbol and the number of shares to buy\n",
    "ticker = \"AAPL\"\n",
    "number_of_shares = 1\n",
    "\n",
    "# Make API call\n",
    "signals_df = api.get_bars(ticker, \"5Min\", \"2022-08-22\", \"2022-10-14\", adjustment='raw').df\n",
    "# Reorganize the DataFrame\n",
    "signals_df = pd.concat([signals_df], axis=1, keys=[\"TSLA\"])\n",
    "\n",
    "# Drop the Multi-Index from the DataFrame\n",
    "signals_df.columns = signals_df.columns.droplevel(0)\n",
    "\n",
    "# create a seperate dataframe for signals\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setup EMAs for crosses\n",
    "longest_MA_window = 200\n",
    "signals_df[\"9EMA\"] = TA.EMA(signals_df, 9)\n",
    "signals_df[\"20EMA\"] = TA.EMA(signals_df, 20)\n",
    "signals_df[\"50EMA\"] = TA.EMA(signals_df, 50)\n",
    "signals_df[\"200SMA\"] = TA.SMA(signals_df, longest_MA_window)\n",
    "\n",
    "# Setup Indicators\n",
    "signals_df[\"ATR\"] = TA.ATR(signals_df)\n",
    "bbands_df = TA.BBANDS(signals_df)\n",
    "macd_df = TA.MACD(signals_df)\n",
    "signals_df[\"RSI\"] = TA.RSI(signals_df)\n",
    "\n",
    "# join macd and bbands Dataframes to signals_df\n",
    "bbands_df = pd.concat([bbands_df, macd_df], axis=1)\n",
    "signals_df = pd.concat([signals_df, bbands_df], axis=1)\n",
    "signals_df.drop(columns=\"SIGNAL\", inplace=True)\n",
    "\n",
    "# Review DataFrame\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete or continuous features (techinal indicators) may be used\n",
    "continuous_features = [\"volume\", \"trade_count\", \"vwap\", \"9EMA\", \"20EMA\", \"50EMA\", \"200SMA\", \"ATR\", \"RSI\", \"BB_UPPER\", \"BB_LOWER\", \"MACD\"]\n",
    "discrete_features = [\"Bollinger_Bands_Above_Upper_BB\", \"Bollinger_Bands_Below_Lower_BB\", \"9EMA/20EMA_Cross, 9EMA>20EMA\", \"9EMA/20EMA_Cross, 9EMA<20EMA\", \"50EMA/200SMA_Cross, 50EMA>200SMA\", \"50EMA/200SMA_Cross, 50EMA<200SMA\", \"RSI_Over_70\", \"RSI_Under_30\", \"VWAP_Cross_From_Above\", \"VWAP_Cross_From_Below\"]\n",
    "all_features = [\"volume\", \"trade_count\", \"vwap\", \"9EMA\", \"20EMA\", \"50EMA\", \"200SMA\", \"ATR\", \"RSI\", \"BB_UPPER\", \"BB_MIDDLE\", \"BB_LOWER\", \"MACD\", \"Bollinger_Bands_Above_Upper_BB\", \"Bollinger_Bands_Below_Lower_BB\", \"9EMA/20EMA_Cross, 9EMA>20EMA\", \"9EMA/20EMA_Cross, 9EMA<20EMA\", \"50EMA/200SMA_Cross, 50EMA>200SMA\", \"50EMA/200SMA_Cross, 50EMA<200SMA\", \"RSI_Over_70\", \"RSI_Under_30\", \"VWAP_Cross_From_Above\", \"VWAP_Cross_From_Below\"]\n",
    "\n",
    "for feature in discrete_features:\n",
    "    signals_df[feature] = 0.0\n",
    "\n",
    "# Review DataFrame\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the trading signals 1 (entry) or -1 (exit) for a long position trading algorithm\n",
    "# where -1 is when the Close price is less than the BB_LOWER window\n",
    "# where 1 is when the Close price is greater the the BB_UPPER window\n",
    "for index, row in signals_df.iterrows():\n",
    "    if row[\"close\"] < row[\"BB_LOWER\"]:\n",
    "        signals_df.loc[index, \"Bollinger_Bands_Below_Lower_BB\"] = 1\n",
    "    if row[\"close\"] > row[\"BB_UPPER\"]:\n",
    "        signals_df.loc[index,\"Bollinger_Bands_Above_Upper_BB\"] = 1\n",
    "\n",
    "# Generate the trading signal 1 or 0\n",
    "# where 1 is when the Short window is greater than (or crosses over) the Long Window\n",
    "# where 0 is when the Short window is under the Long window\n",
    "signals_df[\"9EMA/20EMA_Cross, 9EMA>20EMA\"][9:] = np.where(\n",
    "    signals_df[\"9EMA\"][9:] > signals_df[\"20EMA\"][9:], 1.0, 0.0)\n",
    "# Calculate the points in time at which a position should be taken, 1 or -1, when there is a cross\n",
    "signals_df[\"9EMA/20EMA_Cross, 9EMA>20EMA\"] = signals_df[\"9EMA/20EMA_Cross, 9EMA>20EMA\"].diff()\n",
    "signals_df[\"9EMA/20EMA_Cross, 9EMA<20EMA\"] = (signals_df[\"9EMA/20EMA_Cross, 9EMA>20EMA\"]) * -1\n",
    "\n",
    "# Generate the trading signal 1 or 0,\n",
    "# where 1 is when the Short window is greater than (or crosses over) the Long Window\n",
    "# where 0 is when the Short window is under the Long window\n",
    "signals_df[\"50EMA/200SMA_Cross, 50EMA>200SMA\"][50:] = np.where(\n",
    "    signals_df[\"50EMA\"][50:] > signals_df[\"200SMA\"][50:], 1.0, 0.0)\n",
    "# Calculate the points in time at which a position should be taken, 1 or -1, when the 50EMA Crosses the 200SMA\n",
    "signals_df[\"50EMA/200SMA_Cross, 50EMA>200SMA\"] = signals_df[\"50EMA/200SMA_Cross, 50EMA>200SMA\"].diff()\n",
    "signals_df[\"50EMA/200SMA_Cross, 50EMA<200SMA\"] = (signals_df[\"50EMA/200SMA_Cross, 50EMA>200SMA\"]) * -1\n",
    "\n",
    "# WORK IN PROGRESS - WILL ADD SOON\n",
    "# # Generate the trading signal 1 or 0,\n",
    "# # where 1 is when the MACD is Increasing\n",
    "# # where 0 is when the MACD is Decreasing\n",
    "# n = signals_df[\"MACD_Rate\"].index\n",
    "# signals_df[\"MACD_Rate\"] = np.where(\n",
    "#     signals_df[\"MACD\"][n+1] > signals_df[\"MACD\"][n], 1.0, 0.0)\n",
    "# # Calculate the points in time at which a position should be taken, 1 or -1\n",
    "# signals_df[\"MACD_Rate\"] = signals_df[\"MACD_Rate\"].diff()\n",
    "\n",
    "# Generate the trading signals 1 (entry) or -1 (exit) for a long position trading algorithm\n",
    "# where -1 is when the RSI is below 30\n",
    "# where 1 is when the RSI is above 70\n",
    "for index, row in signals_df.iterrows():\n",
    "    if 30 > row[\"RSI\"]:\n",
    "        signals_df.loc[index, \"RSI_Under_30\"] = 1\n",
    "    if 70 < row[\"RSI\"]:\n",
    "        signals_df.loc[index,\"RSI_Over_70\"] = 1\n",
    "\n",
    "# Generate the trading signal 1 or 0,\n",
    "# where 1 is when the price is above VWAP\n",
    "# where 0 is when the price is below VWAP\n",
    "signals_df[\"VWAP_Cross_From_Above\"] = np.where(\n",
    "    signals_df[\"vwap\"] <= signals_df[\"close\"], 1.0, 0)\n",
    "# Calculate the points in time at which a position should be taken, 1 or -1, when price crosses VWAP\n",
    "signals_df[\"VWAP_Cross_From_Above\"] = signals_df[\"VWAP_Cross_From_Above\"].diff()\n",
    "signals_df[\"VWAP_Cross_From_Below\"] = (signals_df[\"VWAP_Cross_From_Above\"]) * -1\n",
    "\n",
    "# Exit is the labeled target for ML, Exit Price is for use in Pnl Metrics\n",
    "signals_df[\"Exit Price\"] = 0\n",
    "signals_df[\"Exit\"] = 0\n",
    "\n",
    "# Review DataFrame\n",
    "signals_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create the exit column, our \"y\", for use in supervised ML\n",
    "# How many rows are in the signals_df? for use in modifying DataFrame\n",
    "num_rows_in_df = signals_df.shape[0]\n",
    "\n",
    "# reward:risk ratio\n",
    "reward = 3\n",
    "risk = 1\n",
    "\n",
    "# we also figure out our exit price\n",
    "# hitting target price before the stop price signals a win and will be 1\n",
    "# hitting stop price before hitting the target price signals a loss and will be -1\n",
    "# loop thru the dataframe, from the longest_MA_window to the end (num_rows_in_df) to avoid NaN values\n",
    "for j in range(longest_MA_window, num_rows_in_df):\n",
    "    # entries will be on candle close\n",
    "    entry = signals_df[\"close\"].iloc[j]\n",
    "    # calculate volatility for each candle\n",
    "    atr = signals_df[\"ATR\"].iloc[j]\n",
    "    # stop is entry price minus the average volatility for the entry period\n",
    "    stop = entry - (risk * atr)\n",
    "    # target is entry price plus the average volatility for the entry period times a multiplier\n",
    "    target = entry + (reward * atr)\n",
    "    # loop again thru the dataset to compare j entry price to future closing prices to see if we hit target or stop\n",
    "    for k in range(j + 1, num_rows_in_df):\n",
    "        # current low of the candle\n",
    "        curr_low = signals_df[\"low\"].iloc[k]\n",
    "        # current high of the candle\n",
    "        curr_high = signals_df[\"high\"].iloc[k]\n",
    "        # record and break if we hit stop or target, if not we check the next k period\n",
    "        # if current low breaks our stop we should've sold: -1 in our \"Exit\" column\n",
    "        if curr_low <= stop:\n",
    "            signals_df[\"Exit Price\"].iloc[j] = stop\n",
    "            signals_df[\"Exit\"].iloc[j] = -1\n",
    "            # if we hit the stop break the inner loop to check the next row\n",
    "            break\n",
    "        # if current high breaks our target we should've sold: +1 in our \"Exit\" column\n",
    "        elif curr_high >= target:\n",
    "            signals_df[\"Exit Price\"].iloc[j] = target\n",
    "            signals_df[\"Exit\"].iloc[j] = 1\n",
    "            # if we hit the target break the inner loop to check the next row\n",
    "            break\n",
    "\n",
    "# drop beginning columns to avoid NaN values from EMA/SMA calculations\n",
    "signals_df = signals_df[longest_MA_window:]\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is potentially-unwanted zeros in the dataframe\n",
    "signals_df[\"Exit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all unwanted zeros from the exit column\n",
    "signals_df = signals_df.loc[signals_df[\"Exit\"] != 0]\n",
    "signals_df[\"Exit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in discrete_features:\n",
    "    print(signals_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in discrete_features:\n",
    "    signals_df[i] = signals_df[i].replace(-0, 0)\n",
    "    signals_df[i] = signals_df[i].replace(-1, 0)\n",
    "    print(signals_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_begin = str(signals_df.index.min())\n",
    "training_end = str(signals_df.index.min() + DateOffset(months=1))\n",
    "\n",
    "training_begin, training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose if you want continuous or discrete features\n",
    "discrete_X = signals_df[discrete_features]\n",
    "\n",
    "# 1 means a buy would've produced a profit, -1 means a sale would've produced a profit\n",
    "discrete_y = signals_df[\"Exit\"]\n",
    "discrete_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "discrete_X_train = discrete_X.loc[training_begin: training_end]\n",
    "discrete_y_train = discrete_y.loc[training_begin: training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "discrete_X_test = discrete_X.loc[training_end:]\n",
    "discrete_y_test = discrete_y.loc[training_end:]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_rus = RandomUnderSampler(random_state=1)\n",
    "undersampled_discrete_X_train, undersampled_discrete_y_train = discrete_rus.fit_resample(discrete_X_train, discrete_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose if you want continuous or discrete features\n",
    "continuous_X = signals_df[continuous_features]\n",
    "\n",
    "# 1 means a buy would've produced a profit, -1 means a sale would've produced a profit\n",
    "continuous_y = signals_df[\"Exit\"]\n",
    "continuous_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "continuous_X_train = continuous_X.loc[training_begin: training_end]\n",
    "continuous_y_train = continuous_y.loc[training_begin: training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "continuous_X_test = continuous_X.loc[training_end:]\n",
    "continuous_y_test = continuous_y.loc[training_end:]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the continuous data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(continuous_X_train)\n",
    "continuous_X_train_scaled = X_scaler.transform(continuous_X_train)\n",
    "continuous_X_test_scaled = X_scaler.transform(continuous_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_rus = RandomUnderSampler(random_state=1)\n",
    "undersampled_continuous_X_train_scaled, undersampled_continuous_y_train = continuous_rus.fit_resample(continuous_X_train_scaled, continuous_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TIMS SVC MODEL STARTS HERE\n",
    "# Imports\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier model\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "svm_model = svm_model.fit(undersampled_continuous_X_train_scaled, undersampled_continuous_y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions = svm_model.predict(undersampled_continuous_X_train_scaled)\n",
    "\n",
    "# Display the sample predictions\n",
    "training_signal_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a classification report\n",
    "svm_training_report = classification_report(undersampled_continuous_y_train, training_signal_predictions)\n",
    "print(svm_training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Use the trained model to predict the trading signals for the testing data.\n",
    "svm_testing_signal_predictions = svm_model.predict(continuous_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Evaluate the model's ability to predict the trading signal for the testing data\n",
    "svm_testing_report = classification_report(continuous_y_test, svm_testing_signal_predictions)\n",
    "print(svm_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARANDIS SGD MODEL STARTS HERE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the classifier model\n",
    "SGD_model = SGDClassifier(random_state=0)\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "SGD_model.fit(undersampled_continuous_X_train_scaled, undersampled_continuous_y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "SGD_training_predictions = SGD_model.predict(undersampled_continuous_X_train_scaled)\n",
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "SGD_testing_signal_predictions = SGD_model.predict(continuous_X_test_scaled)\n",
    "# Display the sample predictions\n",
    "SGD_training_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_training_report = classification_report(undersampled_continuous_y_train, SGD_training_predictions)\n",
    "print(SGD_training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_testing_report = classification_report(continuous_y_test, SGD_testing_signal_predictions)\n",
    "print(SGD_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAVIDS RF MODEL STARTS HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree classifier instance\n",
    "rf_model = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "rf_model = rf_model.fit(undersampled_discrete_X_train, undersampled_discrete_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(discrete_X_test)\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "rf_training_signal_predictions = rf_model.predict(undersampled_discrete_X_train)\n",
    "rf_testing_signal_predictions = rf_model.predict(discrete_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_training_report = classification_report(undersampled_discrete_y_train, rf_training_signal_predictions)\n",
    "print(rf_training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_testing_report = classification_report(discrete_y_test, rf_testing_signal_predictions)\n",
    "print(rf_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(\n",
    "    rf_model, out_file=None, feature_names=discrete_X.columns, class_names=[\"1\", \"-1\"], filled=True\n",
    ")\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When saving the image, Path() is not used because graph.write_<file_type>() must take a string object\n",
    "\n",
    "# Saving the tree as PDF\n",
    "file_path = \"transactions_tree.pdf\"\n",
    "graph.write_pdf(file_path)\n",
    "\n",
    "# Saving the tree as PNG\n",
    "file_path = \"transactions_tree.png\"\n",
    "graph.write_png(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, discrete_X.columns), reverse=True)\n",
    "importances_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
